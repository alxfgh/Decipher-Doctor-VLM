{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing prescription 1/52\n",
      "Completed processing prescription 2/52\n",
      "Completed processing prescription 3/52\n",
      "Completed processing prescription 4/52\n",
      "Completed processing prescription 5/52\n",
      "Completed processing prescription 6/52\n",
      "Completed processing prescription 7/52\n",
      "Completed processing prescription 8/52\n",
      "Completed processing prescription 9/52\n",
      "Completed processing prescription 10/52\n",
      "Completed processing prescription 11/52\n",
      "Completed processing prescription 12/52\n",
      "Completed processing prescription 13/52\n",
      "Completed processing prescription 14/52\n",
      "Completed processing prescription 15/52\n",
      "Completed processing prescription 16/52\n",
      "Completed processing prescription 17/52\n",
      "Completed processing prescription 18/52\n",
      "Completed processing prescription 19/52\n",
      "Completed processing prescription 20/52\n",
      "Completed processing prescription 21/52\n",
      "Completed processing prescription 22/52\n",
      "Completed processing prescription 23/52\n",
      "Completed processing prescription 24/52\n",
      "Completed processing prescription 25/52\n",
      "Completed processing prescription 26/52\n",
      "Completed processing prescription 27/52\n",
      "Completed processing prescription 28/52\n",
      "Completed processing prescription 29/52\n",
      "Completed processing prescription 30/52\n",
      "Completed processing prescription 31/52\n",
      "Completed processing prescription 32/52\n",
      "Completed processing prescription 33/52\n",
      "Completed processing prescription 34/52\n",
      "Completed processing prescription 35/52\n",
      "Completed processing prescription 36/52\n",
      "Completed processing prescription 37/52\n",
      "Completed processing prescription 38/52\n",
      "Completed processing prescription 39/52\n",
      "Completed processing prescription 40/52\n",
      "Completed processing prescription 41/52\n",
      "Completed processing prescription 42/52\n",
      "Completed processing prescription 43/52\n",
      "Completed processing prescription 44/52\n",
      "Completed processing prescription 45/52\n",
      "Completed processing prescription 46/52\n",
      "Completed processing prescription 47/52\n",
      "Completed processing prescription 48/52\n",
      "Completed processing prescription 49/52\n",
      "Completed processing prescription 50/52\n",
      "Completed processing prescription 51/52\n",
      "Completed processing prescription 52/52\n",
      "7488 synthetic images with different fonts, colormaps, and rotations have been generated and saved in font_dataset.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUTPUT_PATH = 'font_dataset'\n",
    "FONTS_PATH = 'fonts'\n",
    "\n",
    "# Ensure the dataset directory exists\n",
    "Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def load_fonts(fonts_path):\n",
    "    fonts = []\n",
    "    for font_file in os.listdir(fonts_path):\n",
    "        if font_file.lower().endswith(('.ttf', '.otf')):\n",
    "            font_path = os.path.join(fonts_path, font_file)\n",
    "            fonts.append(font_path)\n",
    "    return fonts\n",
    "\n",
    "def generate_line(text, font_path, font_size=32, line_height=64):\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    line_image = Image.new('L', (1, line_height), color=255)\n",
    "    draw = ImageDraw.Draw(line_image)\n",
    "    text_width = draw.textlength(text, font=font)\n",
    "    line_image = Image.new('L', (int(text_width), line_height), color=255)\n",
    "    draw = ImageDraw.Draw(line_image)\n",
    "    draw.text((0, (line_height - font_size) // 2), text, font=font, fill=0)\n",
    "    return line_image\n",
    "\n",
    "def generate_multiline_image(text, fonts, max_width=512, line_spacing=10, canvas_size=512):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "    \n",
    "    adjusted_max_width = max_width + random.randint(-50, 50)\n",
    "    \n",
    "    for word in words:\n",
    "        test_line = current_line + [word]\n",
    "        test_image = generate_line(' '.join(test_line), random.choice(fonts))\n",
    "        \n",
    "        if test_image.width <= adjusted_max_width:\n",
    "            current_line.append(word)\n",
    "        else:\n",
    "            if current_line:\n",
    "                lines.append(' '.join(current_line))\n",
    "            current_line = [word]\n",
    "    \n",
    "    if current_line:\n",
    "        lines.append(' '.join(current_line))\n",
    "\n",
    "    line_images = [generate_line(line, random.choice(fonts)) for line in lines]\n",
    "    max_line_width = max(img.width for img in line_images)\n",
    "    total_height = sum(img.height for img in line_images) + line_spacing * (len(line_images) - 1)\n",
    "    target_width = min(max(max_line_width, canvas_size), adjusted_max_width)\n",
    "    \n",
    "    multiline_image = Image.new('L', (target_width, total_height), color=255)\n",
    "    y_offset = 0\n",
    "    \n",
    "    for line_img in line_images:\n",
    "        multiline_image.paste(line_img, ((target_width - line_img.width) // 2, y_offset))\n",
    "        y_offset += line_img.height + line_spacing\n",
    "    \n",
    "    scale_factor = random.uniform(0.7, 0.9)\n",
    "    resized_image = multiline_image.resize(\n",
    "        (int(multiline_image.width * scale_factor), int(multiline_image.height * scale_factor)), Image.LANCZOS\n",
    "    )\n",
    "    \n",
    "    text_representation = '\\n'.join(lines)\n",
    "    \n",
    "    return resized_image, text_representation\n",
    "\n",
    "def apply_color_map(image, cmap_name):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    normalized_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    colored_image = cmap(normalized_image)\n",
    "    colored_image = np.uint8(colored_image[:, :, :3] * 255)\n",
    "    \n",
    "    return Image.fromarray(colored_image)\n",
    "\n",
    "def ensure_final_size(image, target_size=512):\n",
    "    return image.resize((target_size, target_size), Image.LANCZOS)\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.replace('.', '').replace('-', '')\n",
    "\n",
    "# Load fonts\n",
    "fonts = load_fonts(FONTS_PATH)\n",
    "\n",
    "# Load prescriptions from prescriptions_flat.json\n",
    "prescriptions_path = 'prescriptions_flat.json'\n",
    "\n",
    "with open(prescriptions_path, 'r') as f:\n",
    "    prescriptions = json.load(f)\n",
    "\n",
    "# Synthetic data generation parameters\n",
    "num_splits = 6\n",
    "cmaps = ['gray', 'viridis', 'plasma', 'inferno', 'magma', 'cividis']\n",
    "canvas_size = 512\n",
    "\n",
    "image_data = []\n",
    "\n",
    "for idx, prescription in enumerate(prescriptions):\n",
    "    text = clean_text(prescription)\n",
    "    \n",
    "    for split_idx in range(num_splits):\n",
    "        image, text_representation = generate_multiline_image(text, fonts, canvas_size=canvas_size)\n",
    "        \n",
    "        for cmap in cmaps:\n",
    "            for rotation_idx in range(4):\n",
    "                rotated_image = image.rotate(random.uniform(-15, 15), resample=Image.BILINEAR, expand=True)\n",
    "                colored_image = apply_color_map(rotated_image, cmap)\n",
    "                final_image = ensure_final_size(colored_image)\n",
    "                \n",
    "                image_filename = f\"font_image_{idx+1}_split{split_idx+1}_{cmap}_rot{rotation_idx}.png\"\n",
    "                image_path = os.path.join(OUTPUT_PATH, image_filename).replace('\\\\', '/')\n",
    "                final_image.save(image_path)\n",
    "                \n",
    "                data_entry = {\n",
    "                    \"query\": \"<image>what does this say?\",\n",
    "                    \"response\": text_representation,\n",
    "                    \"images\": [image_path]\n",
    "                }\n",
    "                image_data.append(data_entry)\n",
    "\n",
    "    print(f\"Completed processing prescription {idx + 1}/{len(prescriptions)}\")\n",
    "\n",
    "# Save dataset to JSON file in the root directory\n",
    "json_path = 'font_dataset.json'\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(image_data, f, indent=4)\n",
    "\n",
    "print(f\"{num_splits * len(cmaps) * 4 * len(prescriptions)} synthetic images with different fonts, colormaps, and rotations have been generated and saved in {OUTPUT_PATH}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation sets created: 17978 train samples, 1998 validation samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# Load the dataset.json\n",
    "with open('dataset.json', 'r') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "# Load the synthetic_notes_dataset.json\n",
    "with open('synthetic_notes_dataset.json', 'r') as f:\n",
    "    synthetic_notes_data = json.load(f)\n",
    "\n",
    "with open('font_dataset.json', 'r') as f:\n",
    "    font_dataset = json.load(f)\n",
    "\n",
    "# Combine the two datasets\n",
    "combined_dataset = dataset + synthetic_notes_data + font_dataset\n",
    "\n",
    "# Shuffle the combined dataset to ensure randomness\n",
    "random.shuffle(combined_dataset)\n",
    "\n",
    "# Split the combined dataset into 90% train and 10% validation\n",
    "split_index = int(0.9 * len(combined_dataset))\n",
    "train_data = combined_dataset[:split_index]\n",
    "val_data = combined_dataset[split_index:]\n",
    "\n",
    "# Save the train.json\n",
    "with open('train.json', 'w') as f:\n",
    "    json.dump(train_data, f, indent=4)\n",
    "\n",
    "# Save the val.json\n",
    "with open('val.json', 'w') as f:\n",
    "    json.dump(val_data, f, indent=4)\n",
    "\n",
    "print(f\"Train and validation sets created: {len(train_data)} train samples, {len(val_data)} validation samples.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
